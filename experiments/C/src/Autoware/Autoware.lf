/**
 * This Lingua Franca (LF) program simulates an autonomous driving system inspired
 * by Autoware's general graph structure and constraints. The system involves two
 * sensors, a Camera and a LIDAR, generating periodic image and point-cloud data
 * respectively. These data are processed by two object detection reactors, which
 * simulate GPU computation using simulated delays and threading. The detected
 * objects from both the image and LIDAR data are then merged in a DataFusion
 * reactor. This fusion reactor is designed to handle the arrival of data from both
 * inputs before proceeding, implementing a choke point that collapses multiple
 * logical timelines into one.  
 * 
 * The fused data is passed to a Semantics reactor, which makes driving decisions
 * based on the fused data, and the resultant actuation command is passed to an
 * Actuator reactor. The Actuator reactor operates under a deadline, issuing a
 * warning if this deadline is violated. Moreover, an alternative SafetyBrake path
 * exists that can trigger the actuation based on LIDAR input directly. The whole
 * system is designed to enforce a Logical Execution Time (LET) and meet end-to-end
 * deadlines while taking into account the worst-case execution times of different
 * components. This program offers a high-level simulation of real-time data
 * processing and decision-making in autonomous driving systems. 
 */

// A lingua franca program with Autoware's general graph structure and constraints
// The tentative constraints are:
// - Sensors: Camera(phase=3, period=33) and LIDAR(phase=10, period=10)
// - LET=30ms or alternatively, the relative deadline is 30
// - Sensor Fusion causes merge (choke) points that collapse multiple logical timelines into one.

target C {
  keepalive: false
};

// Send a periodic image out
reactor Camera(offset:time(0), period:time(1 sec)) {
  output image:string;
  timer t(offset, period);

  reaction(t) -> image {=
    lf_set(image, "kitty");
  =}
}

// Send a periodic LIDAR pointcloud out
reactor LIDAR(offset:time(0), period:time(1 sec)) {
  output pointcloud:string;
  timer t(offset, period);

  reaction(t) -> pointcloud {=
    lf_set(pointcloud, "INTERSECTION");
  =}
}

// Simulate object detection on GPU
reactor ImageObjectDetection {
  input image:string;
  output object:string;

  
  state thread_id:pthread_t(0);
  
  preamble {=
  #include <pthread.h>
   
  void camera_callback(void* a) {
    // cudaDeviceSynchronize() and copy back goes here.
    lf_schedule(a, 0);
  }
  // Simulate time passing before a callback occurs instead of executing on GPU.
  void* camera_take_time(void* a) {
    struct timespec sleep_time = {(time_t) 0, (long)5000000}; // WCET for GPU is 5msec
    struct timespec remaining_time;
    nanosleep(&sleep_time, &remaining_time);
    camera_callback(a);
    return NULL;
  }
  pthread_t threadId;
  =}

  physical action CUDA(100 msec);
  reaction(image) -> CUDA {=
    // cudaMalloc(&y_state_d, SIZE);
    // cudaMemcpy(&y_state_d, y_state, SIZE, cudaMemcpyHosttoDevice);
    // kernel<<<1,1>>>(y_state_d);

    /* Busy wait for 2 msecs for now instead of calling CUDA kernels */
    interval_t sleep_time = MSEC(2);
    instant_t start_time = lf_time_physical();
    while (lf_time_physical() < start_time + sleep_time) {};

    pthread_create(&self->thread_id, NULL, &camera_take_time, CUDA);
  =}

  reaction(CUDA) -> object {=
    // cudaMalloc(&y_out_d, SIZE);
    
    // cudaMemcpy(&y_out, results_d, SIZE, cudaMemcpyDevicetoHost);

    // cudaDeviceSynchronize();



    lf_set(object, "DUMMY Results");
  =}
}

// Simulate LIDAR object detection on GPU
reactor LIDARObjectDetection {
  input pointcloud:string;
  output object:string;

     
  state thread_id:pthread_t(0);
  
  preamble {=
  #include <pthread.h>
   
  void LIDAR_callback(void* a) {
    // cudaDeviceSynchronize() and copy back goes here.
    lf_schedule(a, 0);
  }
  // Simulate time passing before a callback occurs instead of executing on GPU.
  void* LIDAR_take_time(void* a) {
    struct timespec sleep_time = {(time_t) 0, (long)12000000}; // WCET for LIDAR GPU is 12 msec
    struct timespec remaining_time;
    nanosleep(&sleep_time, &remaining_time);
    LIDAR_callback(a);
    return NULL;
  }
  pthread_t threadId;
  =}

  logical action CUDA(100 msec, 20 msec);
  reaction(pointcloud) -> CUDA {=
    // self->y_state = y_in;
    // cudaMalloc(&y_state_d, SIZE);
    // cudaMemcpy(&y_state_d, y_state, SIZE, cudaMemcpyHosttoDevice);
    // kernel<<<1,1>>>(y_state_d);
  //printf("LIDAR triggered at %llu\n", lf_time_physical());

    /* Busy wait for 2 msecs for now instead of calling CUDA kernels */
    interval_t sleep_time = MSEC(2);
    instant_t start_time = lf_time_physical();
    while (lf_time_physical() < start_time + sleep_time) {};

    pthread_create(&self->thread_id, NULL, &LIDAR_take_time, CUDA);    
  =}

  reaction(CUDA) -> object {=
    // cudaMalloc(&y_out_d, SIZE);
  //printf("LIDAR triggered at %llu\n", lf_time_physical());
  // printf("LIDAR triggered at %llu\n", lf_time_logical());
    
    // cudaMemcpy(&y_out, results_d, SIZE, cudaMemcpyDevicetoHost);

    // cudaDeviceSynchronize();

    lf_set(object, "Hey look there is a kitty!");
  =}
}


// Fuse LIDAR and Camera detected objects
reactor DataFusion(threshold:time(20 msec)) {
  input imageobject:string;
  input LIDARobject:string;
  output object:string;
  logical action both_ports_are_present(0);

  state tmpImageobject:string("");
  state tmpImageobjectTag:time(0);
  state tmpLIDARobject:string("");
  state tmpLIDARobjectTag:time(0);


  // Handle two ports
  reaction(imageobject, LIDARobject) -> both_ports_are_present {=
    if(imageobject->is_present)
    {
      self->tmpImageobject = imageobject->value;
      self->tmpImageobjectTag = lf_time_logical(); // Store the tag
       
      instant_t window = self->tmpLIDARobjectTag - lf_time_logical();
  
      if(LIDARobject->is_present)
      {
      lf_schedule(both_ports_are_present, 0);
      }
        
       else if(window < (long)1000000)
      {
        lf_schedule(both_ports_are_present, 0);
      }
      else
      {  
        // instant_t elapsed = lf_time_physical() - lf_time_logical(); // How much time has passed - soft
        instant_t elapsed = self->threshold; // How much time has passed - hard
        instant_t remaining = (long)30000000 - elapsed; // How much time is left
        instant_t schedule_in = remaining - (long)8000000; // Combined WCET of the remaining reactions is 8 msec
        lf_schedule(both_ports_are_present, schedule_in);
      }
    // printf("Received image object at %llu physical and %llu logical.\n", lf_time_physical(), lf_time_logical());
    }
    else if(LIDARobject->is_present)
    {
      self->tmpLIDARobject = LIDARobject->value;
      self->tmpLIDARobjectTag = lf_time_logical(); // Store the tag
      
      instant_t window = self->tmpImageobjectTag - lf_time_logical();                                                                                     
      
      if( window < (long)1000000)
      {
        lf_schedule(both_ports_are_present, 0);
      }
      else
      {
      // instant_t elapsed = lf_time_physical() - lf_time_logical(); // How much time has passed - soft
        instant_t elapsed = self->threshold; // How much time has passed - hard
        instant_t remaining = (long)30000000 - elapsed; // How much time is left  
        instant_t schedule_in = remaining - (long)8000000; // Combined WCET of the remaining reactions is 8 msec
        lf_schedule(both_ports_are_present, schedule_in);
      }     
    // printf("Received LIDAR object at %llu physical and %llu logical.\n", lf_time_physical(), lf_time_logical());
    }


  
  =} deadline(threshold) {=
    printf("Deadline violation detected.\n");
  =}

  // Fuse
  reaction(both_ports_are_present) -> object
  {=

    printf("Fusion scheduled at: ( %llu , %llu ).\n", lf_time_physical(), lf_time_logical());
     //printf("Fusion: %llu\n", lf_time_physical());
    /* Busy wait for 2 msecs for now instead of calling CUDA kernels */
    interval_t sleep_time = MSEC(2);
    instant_t start_time = lf_time_physical();
    while (lf_time_physical() < start_time + sleep_time) {};
    lf_set(object, "fused");
  =}
}

// Make driving semantic decisions
reactor Semantics {
  input fusedObject:string;
  output actuation:int;

  reaction(fusedObject) -> actuation {=
    struct timespec sleep_time = {(time_t) 0, (long)6000000};
    struct timespec remaining_time;
    nanosleep(&sleep_time, &remaining_time);
  lf_set(actuation, 5);
  =}
}

reactor Actuator(threshold:time(33 msec)){
  input actuation:int;

  reaction(actuation) {=
    // Do nothing;
    printf("Actuator scheduled at: ( %llu , %llu ).\n", lf_time_physical(), lf_time_logical());
     // printf("Actuator: %llu\n", lf_time_physical());
  =} deadline(threshold) {=
    printf("Deadline violation detected in Actuator.\n");
  =}
}

/* An alternative path exists between the LIDAR and the actuator for the safety brake system */
reactor SafetyBrake {
  input LIDARPointCloud:string;
  output actuation:int;

  reaction(LIDARPointCloud) -> actuation {=
    lf_set(actuation, 5);
  =}
}


// End-to-end daedline should be 33ms
// LET must be enforced with an output period of 33ms
// GPU is used
// Sub-deadlines (i.e., reaction deadlines) must not be violated

main reactor Autoware {
  c = new Camera(offset = 3 msec, period = 33 msec); // Camera has a phase (startup time) of 3 msec and a period of 33 msec
  l = new LIDAR(offset = 10 msec, period = 10 msec); // Lidar has a phase (spooling up time) of 10 msec and a period of 10 msec
  
  iobjectdetection = new ImageObjectDetection();
  c.image -> iobjectdetection.image;

  lobjectdetection = new LIDARObjectDetection();
  l.pointcloud -> lobjectdetection.pointcloud;

  // Choke point
  fuse = new DataFusion();
  iobjectdetection.object -> fuse.imageobject;
  lobjectdetection.object -> fuse.LIDARobject;


  sem = new Semantics();
  fuse.object -> sem.fusedObject;

  ac = new Actuator();
  sem.actuation -> ac.actuation;

  // An alternative path that activates the safety brake system based on LIDAR input
  sb = new SafetyBrake();
  l.pointcloud -> sb.LIDARPointCloud;
  // sb.actuation -> ac.actuation; // Cannot construct the alternative path because actuation may only be connected to a single upstream port

}
