/**
 * This example illustrates the capabilities of an Emergency Sirens Classifier, which can classify
 * two distinct categories: Emergency, and Other
 *
 * @author Vincenzo Barbuto
 */
target Python {
  timeout: 100 sec
}

reactor Microphone {
  physical action send_audio_data
  output audio_data

  state audio_capture_thread  # Thread variables
  state thread_should_be_running

  state buffer_size           # Audio variables
  state sample_rate
  state num_channels
  state overlapping_factor
  state input_length_in_samples
  state interval_between_inference

  preamble {=
    import time as tm
    import sounddevice as sd
    import numpy as np
    import threading

    def audio_capture(self, audio_action, running):

        def callback(indata, frames, time, status):
            if status:
                print(status)

            input_data = self.np.array(indata, dtype=self.np.float32)[:self.buffer_size].reshape((1, self.buffer_size))
            audio_action.schedule(0, input_data)

        with self.sd.InputStream(channels=self.num_channels, samplerate=self.sample_rate, callback=callback, blocksize=self.buffer_size):
            # Press Enter when the shutdown procedure starts to close the audio capturing thread
            print("#" * 50)
            print("Recording started. Press Enter to stop")
            print("#" * 50)
            input()
            print("\nRecording stopped")
  =}

  reaction(startup) -> send_audio_data {=
    # Setup Audio recorders
    self.buffer_size, self.sample_rate, self.num_channels, self.overlapping_factor = 15600, 16000, 1, 0.5
    self.input_length_in_samples =self. buffer_size
    self.interval_between_inference = self.input_length_in_samples * (1 - self.overlapping_factor)

    # Launch Audio Capture Thread
    self.thread_should_be_running = self.threading.Event()
    self.thread_should_be_running.set()

    self.audio_capture_thread = self.threading.Thread(target=self.audio_capture, args=(send_audio_data, self.thread_should_be_running))
    self.audio_capture_thread.start()
  =}

  reaction(send_audio_data) -> audio_data {=
    audio_data.set(send_audio_data.value)
  =}

  reaction(shutdown) {=
    print("*"*32 + " SHUTTING DOWN " + "*"*32)
    self.thread_should_be_running.clear()
    # self.audio_capture_thread.join()
  =}
}

reactor Classifier(model="evds_bin.tflite") {
  state interpreter
  state input_details
  state output_details

  input input_data
  output output_data
  output inference_time

  preamble {=
    import tensorflow as tf
  =}

  reaction(startup) {=
    model_path = f"./{self.model}"
    print(f"Loading the model: {self.model}")
    self.interpreter = self.tf.lite.Interpreter(model_path)
    self.interpreter.allocate_tensors()
    self.input_details = self.interpreter.get_input_details()
    self.output_details = self.interpreter.get_output_details()
  =}

  reaction(input_data) -> output_data, inference_time {=
    # Run inference
    self.interpreter.set_tensor(self.input_details[0]["index"], input_data.value)
    start = lf.time.physical()
    self.interpreter.invoke()
    inference_tm = lf.time.physical() - start
    # Get output results
    results = self.interpreter.get_tensor(self.output_details[1]["index"])
    output_data.set(results)
    inference_time.set(inference_tm)
  =}
}

reactor Actuator(labels = {= ["Emergency", "Other"] =}, window=3) {
  state results_window
  state times
  state count
  state total_times

  input results
  input inference_time

  preamble {=
    import numpy as np
  =}

  reaction(startup) {=
    self.results_window = []
    self.times = []
    self.total_times = []
    self.count = 0
  =}

  reaction(results, inference_time) {=
    self.results_window.append(results.value)
    self.times.append(inference_time.value)
    self.total_times.append(inference_time.value)
    if(((self.count + 1 )%self.window == 0)):
        results_np = self.np.array(self.results_window)
        mean_results = results_np.mean(axis=0)
        result_index = mean_results.argmax()
        times_ms = self.np.mean(self.times) / 1000000
        print("-" * 25 + f"Mean Results for {self.window} Inferences" + "-" * 25)
        print(f"Classification: {self.labels[result_index]} -> {format(mean_results[0][result_index]*100, '.2f')}%")
        print(f"Inference (physical) time: {format(times_ms, '.2f')}ms")
        print("-" * 79)
        self.results_window.clear()
        self.times.clear()
    self.count+=1
  =}

  reaction(shutdown) {=
    avg_time = self.np.mean(self.total_times) / 1000000
    max_time = self.np.max(self.total_times) / 1000000
    min_time = self.np.min(self.total_times) / 1000000
    print("-"*36 + "Summary" + "-"*36)
    print(f"Mean Inference Time: {format(avg_time, '.2f')}ms")
    print(f"Slowest Inference: {format(max_time, '.2f')}ms")
    print(f"Fastes Inference: {format(min_time, '.2f')}ms")
    print("-" * 79)
  =}
}

main reactor {
  mic = new Microphone()
  classifier = new Classifier()
  actuator = new Actuator()

  mic.audio_data -> classifier.input_data
  classifier.output_data, classifier.inference_time -> actuator.results, actuator.inference_time
}
